{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tQdXY7glYHF"
      },
      "source": [
        "# Zagadki"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EI1z21MnlYHH"
      },
      "source": [
        "## Wstęp\n",
        "Zagadki od wieków fascynują ludzi, pobudzając ich umysły do kreatywnego i logicznego myślenia. Od prostych łamigłówek po głębokie zagadki filozoficzne, stanowią one nie tylko formę rozrywki, ale również sztukę rozumienia języka i logicznego wnioskowania. W tym zadaniu będziesz rozwiązywał/a zagadki, polegające na odgadnięciu słowa na podstawie opisu. Wszystkie zagadki wymyślił ChatGPT (ale nie powiemy, która dokładnie wersja i w jaki sposób zachęcona), stąd niektóre mogą być trochę dziwne... Szacujemy, że ludzie są w stanie rozwiązać poprawnie trochę ponad 60% z nich. A jak dobry będzie Twój program?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMtMoxMilYHI"
      },
      "source": [
        "## Zadanie\n",
        "Napisz funckję `answer_riddle` która rozwiąże podaną na wejściu zagadkę. Rozwiązaniem jest zawsze jedno słowo. Przykładowe zagadki:\n",
        "\n",
        "- **zagadka:** kobieta podróżująca środkiem transportu, np. samolotem, pociągiem, statkiem <br>\n",
        "  **odpowiedź:** pasażerka\n",
        "- **zagadka:** emocjonalne uczucie łączące dwie osoby, oparte na zaufaniu, szacunku, trosce i oddaniu<br>\n",
        "  **odpowiedź:** miłość\n",
        "\n",
        "\n",
        "Naszym kryterium będzie `odwrócona średnia harmoniczna` ([Mean Reciprocal Rank](https://en.wikipedia.org/wiki/Mean_reciprocal_rank)), która działa w następujący sposób: <br>\n",
        "Jeżeli na zwróconej przez Twoją funkcję liście znajdzie się prawidłowa odpowiedź, otrzymasz wówczas punkty: dokładnie $\\frac{1}{k}$ punktów, gdzie $k$ jest pozycją słowa na liście. W szczególności, jeżeli Twój program zgadnie słowo (czyli umieści je na pierwszej pozycji), to otrzymasz 1 punkt. Ostatecznym kryterium jest uśredniona liczba punktów ze wszystkich zagadek.\n",
        "\n",
        "Powyższe kryterium jest zaimplementowane poniżej przez nas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_endlxUlYHJ"
      },
      "source": [
        "## Ograniczenia\n",
        "- Twoje finalne rozwiązanie będzie testowane w środowisku **bez** GPU.\n",
        "- Twoja funkcja powinna działać na tyle szybko, aby program był w stanie udzielić odpowiedzi na 100 zagadek w maksymalnie 2 minuty bez użycia GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hcoi6UHlYHJ"
      },
      "source": [
        "## Dane\n",
        "Dane dostępne dla Ciebie w tym zadaniu to:\n",
        "* `zagadki_do_testow_clean.txt` - około 2000 przykładowych zagadek\n",
        "* `plwiktionary_definitions_clean.txt` -  plik z definicjami słów wziętymi z [pl.wiktionary.org](https://pl.wiktionary.org/wiki/pl). Z wszystkich definicji z pl.wiktionary.org wzięliśmy definicje 8094 najbardziej popularnych rzeczowników (częstości liczone zgodnie z korpusem https://2018.poleval.pl/index.php/tasks#task3). Uwaga: poprawne rozwiązanie każdej zagadki znajduje się w tym pliku!\n",
        "\n",
        "* `superbazy_clean.txt` - formy bazowe polskich słów, przygotowane na podstawie projektu https://github.com/morfologik/polimorfologik\n",
        "\n",
        "* Wektory osadzeń słów bazowych, wytrenowane modelem Word2Vec z biblioteki Gensim, na korpusie PolEval 2018 Task3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNKvpurTlYHK"
      },
      "source": [
        "## Uwagi i wskazówki\n",
        "- Dla każdej zagadki, Twoja funkcja powinna zwrócić listę słów (co najwyżej 20), w kolejności od najbardziej (wg Twojego programu) prawdopodobnej odpowiedzi na zagadkę, do najmniej.\n",
        "- Twoje rozwiazanie bedzie testowane bez dostepu do internetu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruoC9CHilYHK"
      },
      "source": [
        "## Pliki Zgłoszeniowe\n",
        "Tylko ten notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQOGVaHolYHK"
      },
      "source": [
        "## Ewaluacja\n",
        "Pamiętaj, że podczas sprawdzania flaga `FINAL_EVALUATION_MODE` zostanie ustawiona na `True`. Za pomocą skryptu `validation_script.py` będziesz upewnić się, że Twoje rozwiązanie zostanie prawidłowo wykonane na naszych serwerach oceniających.\n",
        "\n",
        "Za to zadanie możesz zdobyć pomiędzy 0 i 1.5 punktu. Zdobędziesz 0 punktów jeśli wartość kryterium `mean reciprocal rank` na zbiorze testowym wyniesie poniżej 0.02, a 1.5 punktu jeśli wyniesie powyżej 0.3. Pomiędzy tymi wartościami, wynik rośnie liniowo z wartością kryterium."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4my6wkulYHL"
      },
      "source": [
        "# Kod startowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QgNjB5h-lYHL"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI PODCZAS WYSYŁANIA ##########################\n",
        "FINAL_EVALUATION_MODE = False\n",
        "# W czasie sprawdzania Twojego rozwiązania, zmienimy tę wartość na True\n",
        "# Wartość tej flagi M U S I zostać ustawiona na False w rozwiązaniu, które nam nadeślesz!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd72W-D-nNM-",
        "outputId": "15589517-6fb5-4f37-93bc-f56c98a03981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install --upgrade numpy gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "u9ZbDMjYlYHM"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize as tokenize\n",
        "from collections import defaultdict as dd\n",
        "import math\n",
        "from gensim.models import Word2Vec\n",
        "import gdown\n",
        "import random\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coRtelZDlYHM"
      },
      "source": [
        "## Ładowanie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "isZc_5KYlYHM"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "path_to_data = 'data/'\n",
        "\n",
        "bases = {}\n",
        "# Dictionary mapping words to their base words\n",
        "all_word_definitions = dd(list)\n",
        "# Dictionary containing all base words inverse document frequency\n",
        "base_idf = dd(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLjC-Q91T4ON"
      },
      "source": [
        "##Ta funkcja służy do sprowadzenia słowa do jego podstawowej (kanonicznej) formy, czyli tzw. lematyzacji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OJP9jn25lYHM"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def get_word_base(word):\n",
        "    global bases\n",
        "    word = word.lower()\n",
        "    ret = bases.get(word)\n",
        "    if ret:\n",
        "        return ret\n",
        "    return word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5EIGbnyT8rG"
      },
      "source": [
        "## Pobranie danych"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WipYGiH5lYHN",
        "outputId": "edef4161-d945-424a-c212-8404e41eb1ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file 1dCYKzdg6TihyckNM9Zxr1g9lWT1BzDXI plwiktionary_definitions_clean.txt\n",
            "Processing file 1q6Ki5Y66gugM30oFcCtJj7ocMJymskSk superbazy_clean.txt\n",
            "Processing file 1GZPNIR16bxFnzvbIYDLacn8TcKwiGnIh w2v_polish_lemmas.model\n",
            "Processing file 1C-V5TgIAHUJp_FLD-bvks6LmMkrfQpzC w2v_polish_lemmas.model.syn1neg.npy\n",
            "Processing file 1RY0Ftfx_-nPUbddYCvHq9p8yCcXbUrYS w2v_polish_lemmas.model.wv.vectors.npy\n",
            "Processing file 18wrF9VyESTvIT9Z_TqUd_2wV4lP2As3t zagadki_do_testow_clean.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dCYKzdg6TihyckNM9Zxr1g9lWT1BzDXI\n",
            "To: /content/data/zagadki/plwiktionary_definitions_clean.txt\n",
            "100%|██████████| 1.59M/1.59M [00:00<00:00, 59.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1q6Ki5Y66gugM30oFcCtJj7ocMJymskSk\n",
            "To: /content/data/zagadki/superbazy_clean.txt\n",
            "100%|██████████| 43.7M/43.7M [00:00<00:00, 84.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GZPNIR16bxFnzvbIYDLacn8TcKwiGnIh\n",
            "To: /content/data/zagadki/w2v_polish_lemmas.model\n",
            "100%|██████████| 40.8M/40.8M [00:00<00:00, 58.2MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1C-V5TgIAHUJp_FLD-bvks6LmMkrfQpzC\n",
            "From (redirected): https://drive.google.com/uc?id=1C-V5TgIAHUJp_FLD-bvks6LmMkrfQpzC&confirm=t&uuid=24b28e28-d660-4812-b936-c0a7d65f411d\n",
            "To: /content/data/zagadki/w2v_polish_lemmas.model.syn1neg.npy\n",
            "100%|██████████| 958M/958M [00:14<00:00, 66.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1RY0Ftfx_-nPUbddYCvHq9p8yCcXbUrYS\n",
            "From (redirected): https://drive.google.com/uc?id=1RY0Ftfx_-nPUbddYCvHq9p8yCcXbUrYS&confirm=t&uuid=4b7a6c42-37f9-4a04-a394-e52e26cb0cf8\n",
            "To: /content/data/zagadki/w2v_polish_lemmas.model.wv.vectors.npy\n",
            "100%|██████████| 958M/958M [00:13<00:00, 70.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18wrF9VyESTvIT9Z_TqUd_2wV4lP2As3t\n",
            "To: /content/data/zagadki/zagadki_do_testow_clean.txt\n",
            "100%|██████████| 269k/269k [00:00<00:00, 69.0MB/s]\n",
            "Download completed\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    if not os.path.exists(f\"{path_to_data}/zagadki/w2v_polish_lemmas.model\") \\\n",
        "        or not os.path.exists(f\"{path_to_data}/zagadki/w2v_polish_lemmas.model.syn1neg.npy\") \\\n",
        "        or not os.path.exists(f\"{path_to_data}/zagadki/w2v_polish_lemmas.model.wv.vectors.npy\"):\n",
        "            gdown.download_folder(url=\"https://drive.google.com/drive/folders/1P72og_ORfL3Ojf27n-g06DT0ENduPy8C?usp=sharing\", output=f\"./{path_to_data}\")\n",
        "    nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VINSh5adUBg9"
      },
      "source": [
        "## Wczytywanie lematów do słownika bases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gGjWOeaLlYHN"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "for x in open(f'{path_to_data}/zagadki/superbazy_clean.txt'):\n",
        "    word,base = x.lower().split()\n",
        "    bases[word] = base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v7PfHrAUIyd"
      },
      "source": [
        "## Ładowanie modelu Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pn_kR3jylYHN"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "model = Word2Vec.load(f'{path_to_data}/zagadki/w2v_polish_lemmas.model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDwNcX5-UWZg"
      },
      "source": [
        "## Wczytywanie definicji słów + wstępne IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_dU0eLHlYHN",
        "outputId": "db40a164-8104-4874-8bd5-5b2788f2bb4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "for x in open(f'{path_to_data}/zagadki/plwiktionary_definitions_clean.txt'):\n",
        "    word, definition = x.split('###')\n",
        "    L = word.split()\n",
        "    if len(L) == 1:\n",
        "        word = L[0]\n",
        "\n",
        "        definition = set(tokenize(definition.lower()))\n",
        "        all_word_definitions[word].append(definition)\n",
        "        for word in set(definition):\n",
        "            base_idf[get_word_base(word)] += 1\n",
        "\n",
        "\n",
        "for base in base_idf:\n",
        "    base_idf[base] = -math.log(base_idf[base] / len(all_word_definitions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRC1TzinVDt1"
      },
      "source": [
        "## Wczytywanie zagadek i odpowiedzi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ix2Iqs_ulYHO"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "answers = []\n",
        "queries = []\n",
        "\n",
        "with open(f'{path_to_data}/zagadki/zagadki_do_testow_clean.txt') as file:\n",
        "    for line in file:\n",
        "        line = line.replace(';;', '').split()\n",
        "        answers.append(line[0])\n",
        "        queries.append(tokenize(' '.join(line[1:])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DThkrVmlYHO"
      },
      "source": [
        "## Kod z kryteriami oceniającymi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IbFUaxg0lYHO"
      },
      "outputs": [],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "def mean_reciprocal_rank(real_answers, computed_answers, K=20):\n",
        "    positions = []\n",
        "\n",
        "    for real_answer, computed_answer in zip(real_answers, computed_answers):\n",
        "        if real_answer in computed_answer[:K]:\n",
        "            pos = computed_answer.index(real_answer) + 1\n",
        "            positions.append(1/pos)\n",
        "\n",
        "    mrr = sum(positions) / len(real_answers)\n",
        "    print ('Mean Reciprocal Rank =', mrr)\n",
        "\n",
        "    return mrr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_yYRWnalYHO"
      },
      "source": [
        "# Twoje rozwiązanie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFOkiXZulYHO"
      },
      "source": [
        "To jest jedyna sekcja, w której musisz coś zrobić."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "19FmXDydrWVt"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# ------------------------\n",
        "# Stałe i słowa stopu\n",
        "# ------------------------\n",
        "\n",
        "STOP_WORDS = [ \"a\", \"aby\", \"ach\", \"acz\", \"aczkolwiek\", \"aj\", \"albo\", \"ale\", \"ależ\", \"ani\", \"aż\", \"bardziej\", \"bardzo\",\n",
        "               \"bez\", \"bo\", \"bowiem\", \"by\", \"byli\", \"bym\", \"bynajmniej\", \"być\", \"był\", \"była\", \"było\", \"były\", \"będzie\",\n",
        "               \"będą\", \"cali\", \"cała\", \"cały\", \"chce\", \"choć\", \"ci\", \"ciebie\", \"cię\", \"co\", \"cokolwiek\", \"coraz\", \"coś\",\n",
        "               \"czasami\", \"czasem\", \"czemu\", \"czy\", \"czyli\", \"często\", \"daleko\", \"dla\", \"dlaczego\", \"dlatego\", \"do\",\n",
        "               \"dobrze\", \"dokąd\", \"dość\", \"dr\", \"dużo\", \"dwa\", \"dwaj\", \"dwie\", \"dwoje\", \"dzisiaj\", \"dziś\", \"gdy\",\n",
        "               \"gdyby\", \"gdyż\", \"gdzie\", \"gdziekolwiek\", \"gdzieś\", \"go\", \"godz\", \"hab\", \"i\", \"ich\", \"ii\", \"iii\", \"ile\",\n",
        "               \"im\", \"inna\", \"inne\", \"inny\", \"innych\", \"inż\", \"iv\", \"ix\", \"iż\", \"ja\", \"jak\", \"jakaś\", \"jakby\", \"jaki\",\n",
        "               \"jakichś\", \"jakie\", \"jakiś\", \"jakiż\", \"jakkolwiek\", \"jako\", \"jakoś\", \"je\", \"jeden\", \"jedna\", \"jednak\",\n",
        "               \"jednakże\", \"jedno\", \"jednym\", \"jedynie\", \"jego\", \"jej\", \"jemu\", \"jest\", \"jestem\", \"jeszcze\", \"jeśli\",\n",
        "               \"jeżeli\", \"już\", \"ją\", \"każdy\", \"kiedy\", \"kierunku\", \"kilka\", \"kilku\", \"kimś\", \"kto\", \"ktokolwiek\",\n",
        "               \"ktoś\", \"która\", \"które\", \"którego\", \"której\", \"który\", \"których\", \"którym\", \"którzy\", \"ku\", \"lat\", \"lecz\",\n",
        "               \"lub\", \"ma\", \"mają\", \"mam\", \"mamy\", \"mało\", \"mgr\", \"mi\", \"miał\", \"mimo\", \"między\", \"mnie\", \"mną\", \"mogą\",\n",
        "               \"moi\", \"moim\", \"moja\", \"moje\", \"może\", \"możliwe\", \"można\", \"mu\", \"musi\", \"my\", \"mój\", \"na\", \"nad\", \"nam\",\n",
        "               \"nami\", \"nas\", \"nasi\", \"nasz\", \"nasza\", \"nasze\", \"naszego\", \"naszych\", \"natomiast\", \"natychmiast\",\n",
        "               \"nawet\", \"nic\", \"nich\", \"nie\", \"niech\", \"niego\", \"niej\", \"niemu\", \"nigdy\", \"nim\", \"nimi\", \"nią\", \"niż\",\n",
        "               \"no\", \"nowe\", \"np\", \"nr\", \"o\", \"o.o.\", \"obok\", \"od\", \"ok\", \"około\", \"on\", \"ona\", \"one\", \"oni\", \"ono\",\n",
        "               \"oraz\", \"oto\", \"owszem\", \"pan\", \"pana\", \"pani\", \"pl\", \"po\", \"pod\", \"podczas\", \"pomimo\", \"ponad\",\n",
        "               \"ponieważ\", \"powinien\", \"powinna\", \"powinni\", \"powinno\", \"poza\", \"prawie\", \"prof\", \"przecież\", \"przed\",\n",
        "               \"przede\", \"przedtem\", \"przez\", \"przy\", \"raz\", \"razie\", \"roku\", \"również\", \"sam\", \"sama\", \"się\", \"skąd\",\n",
        "               \"sobie\", \"sobą\", \"sposób\", \"swoje\", \"są\", \"ta\", \"tak\", \"taka\", \"taki\", \"takich\", \"takie\", \"także\", \"tam\",\n",
        "               \"te\", \"tego\", \"tej\", \"tel\", \"temu\", \"ten\", \"teraz\", \"też\", \"to\", \"tobie\", \"tobą\", \"toteż\", \"trzeba\",\n",
        "               \"tu\", \"tutaj\", \"twoi\", \"twoim\", \"twoja\", \"twoje\", \"twym\", \"twój\", \"ty\", \"tych\", \"tylko\", \"tym\", \"tys\",\n",
        "               \"tzw\", \"tę\", \"u\", \"ul\", \"vi\", \"vii\", \"viii\", \"vol\", \"w\", \"wam\", \"wami\", \"was\", \"wasi\", \"wasz\", \"wasza\",\n",
        "               \"wasze\", \"we\", \"według\", \"wie\", \"wiele\", \"wielu\", \"więc\", \"więcej\", \"wszyscy\", \"wszystkich\", \"wszystkie\",\n",
        "               \"wszystkim\", \"wszystko\", \"wtedy\", \"www\", \"wy\", \"właśnie\", \"wśród\", \"xi\", \"xii\", \"xiii\", \"xiv\", \"xv\", \"z\",\n",
        "               \"za\", \"zapewne\", \"zawsze\", \"zaś\", \"ze\", \"znowu\", \"znów\", \"został\", \"zł\", \"żaden\", \"żadna\", \"żadne\",\n",
        "               \"żadnych\", \"że\", \"żeby\"]\n",
        "\n",
        "# ------------------------\n",
        "# Przygotowanie danych\n",
        "# ------------------------\n",
        "\n",
        "idf_words = {}\n",
        "word_freq = {}\n",
        "total_word_count = 0\n",
        "all_words = set()\n",
        "num_sentences = 0\n",
        "\n",
        "for definitions in all_word_definitions:\n",
        "    for sentence in all_word_definitions[definitions]:\n",
        "        for word in sentence:\n",
        "            base_word = get_word_base(word)\n",
        "            word_freq[base_word] = word_freq.get(base_word, 0) + 1\n",
        "            total_word_count += 1\n",
        "            all_words.add(base_word)\n",
        "        num_sentences += 1\n",
        "\n",
        "# ------------------------\n",
        "# SIF Weights\n",
        "# ------------------------\n",
        "\n",
        "a = 0.001\n",
        "sif_weights = {word: a / (a + (word_freq.get(word, 0) / total_word_count + 1e-8)) for word in all_words}\n",
        "\n",
        "# ------------------------\n",
        "# Szybsze usuwanie śmieci\n",
        "# ------------------------\n",
        "\n",
        "trash_table = str.maketrans('', '', \";'{}.,\\n()_\")\n",
        "\n",
        "def remove_trash(word):\n",
        "    return word.translate(trash_table)\n",
        "\n",
        "# ------------------------\n",
        "# Embedding bez PCA\n",
        "# ------------------------\n",
        "\n",
        "def sentence_embedding_no_pca(sentence):\n",
        "    avg_vector = np.zeros(200)\n",
        "    valid_word_count = 0\n",
        "\n",
        "    for word in sentence:\n",
        "        word = remove_trash(word)\n",
        "        word = get_word_base(word)\n",
        "        if word not in STOP_WORDS:\n",
        "            vector = model.wv[word] * sif_weights.get(word, a) if word in model.wv else np.zeros(200)\n",
        "            avg_vector += vector\n",
        "            valid_word_count += 1\n",
        "\n",
        "    return avg_vector / valid_word_count if valid_word_count > 0 else avg_vector\n",
        "\n",
        "# ------------------------\n",
        "# Wyliczanie sentence_vectors\n",
        "# ------------------------\n",
        "\n",
        "sentence_vectors = []\n",
        "\n",
        "for definitions in all_word_definitions:\n",
        "    for sentence in all_word_definitions[definitions]:\n",
        "        embedding = sentence_embedding_no_pca(sentence)\n",
        "        sentence_vectors.append(embedding)\n",
        "\n",
        "sentence_vectors = np.array(sentence_vectors)\n",
        "\n",
        "# ------------------------\n",
        "# PCA (z wieloma komponentami)\n",
        "# ------------------------\n",
        "\n",
        "svd = TruncatedSVD(n_components=5, n_iter=7, random_state=42)\n",
        "svd.fit(sentence_vectors)\n",
        "pcs = svd.components_\n",
        "\n",
        "# ------------------------\n",
        "# PCA - usuwanie komponentów\n",
        "# ------------------------\n",
        "\n",
        "def remove_pc(vector, pcs, beta=0.7):\n",
        "    v = vector.copy()\n",
        "    for pc in pcs:\n",
        "        v -= beta * np.dot(pc, v) * pc\n",
        "    return v\n",
        "\n",
        "# ------------------------\n",
        "# Finalne embeddingi\n",
        "# ------------------------\n",
        "\n",
        "def sentence_embedding(sentence):\n",
        "    avg_vector = sentence_embedding_no_pca(sentence)\n",
        "    vector = remove_pc(avg_vector, pcs, beta=0.7)\n",
        "    return vector / np.linalg.norm(vector) if np.linalg.norm(vector) > 0 else vector\n",
        "\n",
        "# ------------------------\n",
        "# Embedding definicji\n",
        "# ------------------------\n",
        "\n",
        "all_def_embeddings = [\n",
        "    (definition, sentence_embedding(sentence))\n",
        "    for definition in all_word_definitions\n",
        "    for sentence in all_word_definitions[definition]\n",
        "]\n",
        "\n",
        "# ------------------------\n",
        "# Metryka cosine similarity\n",
        "# ------------------------\n",
        "\n",
        "def cosine_sim(v1, v2):\n",
        "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-8)\n",
        "\n",
        "# ------------------------\n",
        "# Odpowiadanie na zagadkę\n",
        "# ------------------------\n",
        "\n",
        "def answer_riddle(riddle, K):\n",
        "    riddle_vector = sentence_embedding(riddle)\n",
        "    distances = []\n",
        "\n",
        "    for definition, definition_vector in all_def_embeddings:\n",
        "        sim = cosine_sim(riddle_vector, definition_vector)\n",
        "        distances.append((sim, definition))\n",
        "\n",
        "    distances.sort(reverse=True)  # większe = lepsze\n",
        "    return [definition for _, definition in distances[:K]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "MwvmlLPASBfW"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# ------------------------\n",
        "# Stałe i słowa stopu\n",
        "# ------------------------\n",
        "\n",
        "STOP_WORDS = [ \"a\",\"aby\",\"ach\",\"acz\",\"aczkolwiek\",\"aj\",\"albo\",\"ale\",\"ależ\",\"ani\",\"aż\",\"bardziej\",\"bardzo\",\n",
        "               \"bez\",\"bo\",\"bowiem\",\"by\",\"byli\",\"bym\",\"bynajmniej\",\"być\",\"był\",\"była\",\"było\",\"były\",\"będzie\",\n",
        "               \"będą\",\"cali\",\"cała\",\"cały\",\"chce\",\"choć\",\"ci\",\"ciebie\",\"cię\",\"co\",\"cokolwiek\",\"coraz\",\"coś\",\n",
        "               \"czasami\",\"czasem\",\"czemu\",\"czy\",\"czyli\",\"często\",\"daleko\",\"dla\",\"dlaczego\",\"dlatego\",\"do\",\n",
        "               \"dobrze\",\"dokąd\",\"dość\",\"dr\",\"dużo\",\"dwa\",\"dwaj\",\"dwie\",\"dwoje\",\"dzisiaj\",\"dziś\",\"gdy\",\n",
        "               \"gdyby\",\"gdyż\",\"gdzie\",\"gdziekolwiek\",\"gdzieś\",\"go\",\"godz\",\"hab\",\"i\",\"ich\",\"ii\",\"iii\",\"ile\",\n",
        "               \"im\",\"inna\",\"inne\",\"inny\",\"innych\",\"inż\",\"iv\",\"ix\",\"iż\",\"ja\",\"jak\",\"jakaś\",\"jakby\",\"jaki\",\n",
        "               \"jakichś\",\"jakie\",\"jakiś\",\"jakiż\",\"jakkolwiek\",\"jako\",\"jakoś\",\"je\",\"jeden\",\"jedna\",\"jednak\",\n",
        "               \"jednakże\",\"jedno\",\"jednym\",\"jedynie\",\"jego\",\"jej\",\"jemu\",\"jest\",\"jestem\",\"jeszcze\",\"jeśli\",\n",
        "               \"jeżeli\",\"już\",\"ją\",\"każdy\",\"kiedy\",\"kierunku\",\"kilka\",\"kilku\",\"kimś\",\"kto\",\"ktokolwiek\",\n",
        "               \"ktoś\",\"która\",\"które\",\"którego\",\"której\",\"który\",\"których\",\"którym\",\"którzy\",\"ku\",\"lat\",\"lecz\",\n",
        "               \"lub\",\"ma\",\"mają\",\"mam\",\"mamy\",\"mało\",\"mgr\",\"mi\",\"miał\",\"mimo\",\"między\",\"mnie\",\"mną\",\"mogą\",\n",
        "               \"moi\",\"moim\",\"moja\",\"moje\",\"może\",\"możliwe\",\"można\",\"mu\",\"musi\",\"my\",\"mój\",\"na\",\"nad\",\"nam\",\n",
        "               \"nami\",\"nas\",\"nasi\",\"nasz\",\"nasza\",\"nasze\",\"naszego\",\"naszych\",\"natomiast\",\"natychmiast\",\n",
        "               \"nawet\",\"nic\",\"nich\",\"nie\",\"niech\",\"niego\",\"niej\",\"niemu\",\"nigdy\",\"nim\",\"nimi\",\"nią\",\"niż\",\n",
        "               \"no\",\"nowe\",\"np\",\"nr\",\"o\",\"o.o.\",\"obok\",\"od\",\"ok\",\"około\",\"on\",\"ona\",\"one\",\"oni\",\"ono\",\n",
        "               \"oraz\",\"oto\",\"owszem\",\"pan\",\"pana\",\"pani\",\"pl\",\"po\",\"pod\",\"podczas\",\"pomimo\",\"ponad\",\n",
        "               \"ponieważ\",\"powinien\",\"powinna\",\"powinni\",\"powinno\",\"poza\",\"prawie\",\"prof\",\"przecież\",\"przed\",\n",
        "               \"przede\",\"przedtem\",\"przez\",\"przy\",\"raz\",\"razie\",\"roku\",\"również\",\"sam\",\"sama\",\"się\",\"skąd\",\n",
        "               \"sobie\",\"sobą\",\"sposób\",\"swoje\",\"są\",\"ta\",\"tak\",\"taka\",\"taki\",\"takich\",\"takie\",\"także\",\"tam\",\n",
        "               \"te\",\"tego\",\"tej\",\"tel\",\"temu\",\"ten\",\"teraz\",\"też\",\"to\",\"tobie\",\"tobą\",\"toteż\",\"trzeba\",\n",
        "               \"tu\",\"tutaj\",\"twoi\",\"twoim\",\"twoja\",\"twoje\",\"twym\",\"twój\",\"ty\",\"tych\",\"tylko\",\"tym\",\"tys\",\n",
        "               \"tzw\",\"tę\",\"u\",\"ul\",\"vi\",\"vii\",\"viii\",\"vol\",\"w\",\"wam\",\"wami\",\"was\",\"wasi\",\"wasz\",\"wasza\",\n",
        "               \"wasze\",\"we\",\"według\",\"wie\",\"wiele\",\"wielu\",\"więc\",\"więcej\",\"wszyscy\",\"wszystkich\",\"wszystkie\",\n",
        "               \"wszystkim\",\"wszystko\",\"wtedy\",\"www\",\"wy\",\"właśnie\",\"wśród\",\"xi\",\"xii\",\"xiii\",\"xiv\",\"xv\",\"z\",\n",
        "               \"za\",\"zapewne\",\"zawsze\",\"zaś\",\"ze\",\"znowu\",\"znów\",\"został\",\"zł\",\"żaden\",\"żadna\",\"żadne\",\n",
        "               \"żadnych\",\"że\",\"żeby\"]\n",
        "\n",
        "# ------------------------\n",
        "# Przygotowanie danych\n",
        "# ------------------------\n",
        "\n",
        "idf_words = {}\n",
        "word_freq = {}\n",
        "total_word_count = 0\n",
        "all_words = []\n",
        "num_sentences = 0\n",
        "\n",
        "for definitions in all_word_definitions:\n",
        "    for sentence in all_word_definitions[definitions]:\n",
        "        for word in sentence:\n",
        "            base_word = get_word_base(word)\n",
        "            word_freq[base_word] = word_freq.get(base_word, 0) + 1\n",
        "            total_word_count += 1\n",
        "            if base_word not in all_words:\n",
        "                all_words.append(base_word)\n",
        "        num_sentences += 1\n",
        "\n",
        "a = 0.001\n",
        "sif_weights = {word: a / (a + (word_freq.get(word, 0) / total_word_count + 1e-8)) for word in all_words}\n",
        "\n",
        "for word in all_words:\n",
        "    idf_words[word] = 0\n",
        "\n",
        "for definitions in all_word_definitions:\n",
        "    for sentence in all_word_definitions[definitions]:\n",
        "        added = []\n",
        "        for word in sentence:\n",
        "            base_word = get_word_base(word)\n",
        "            if base_word not in added:\n",
        "                idf_words[base_word] += 1\n",
        "                added.append(base_word)\n",
        "\n",
        "for word in all_words:\n",
        "    idf_words[word] = math.log(num_sentences / idf_words[word], 2)\n",
        "\n",
        "idf_average = sum(idf_words.values()) / len(idf_words)\n",
        "\n",
        "# ------------------------\n",
        "# Funkcje pomocnicze\n",
        "# ------------------------\n",
        "\n",
        "def remove_trash(word):\n",
        "    to_remove = [';', \"'\", '{', '}', '.', ',', '\\n', '(', ')', '_']\n",
        "    for char in to_remove:\n",
        "        word = word.replace(char, '')\n",
        "    return word\n",
        "\n",
        "# ------------------------\n",
        "# Funkcja Sentence_Embeding (bez PCA i z normalizacją)\n",
        "# ------------------------\n",
        "\n",
        "def Sentence_Embeding(sentence):\n",
        "    avg_vector = np.zeros(200)\n",
        "    valid_word_count = 0\n",
        "    for word in sentence:\n",
        "        word = remove_trash(word)\n",
        "        word = get_word_base(word)\n",
        "        if word not in STOP_WORDS:\n",
        "            try:\n",
        "                vector = model.wv[word] * sif_weights.get(word, a)\n",
        "            except Exception as e:\n",
        "                try:\n",
        "                    vector = model.wv[word] * idf_average\n",
        "                except Exception as a:\n",
        "                    vector = np.zeros(200)\n",
        "            avg_vector += vector\n",
        "            valid_word_count += 1\n",
        "    if valid_word_count > 0:\n",
        "        avg_vector /= valid_word_count\n",
        "    # Normalizacja wektora\n",
        "    norm = np.linalg.norm(avg_vector)\n",
        "    if norm > 0:\n",
        "        avg_vector = avg_vector / norm\n",
        "    return avg_vector\n",
        "\n",
        "# ------------------------\n",
        "# Generowanie embeddingów definicji (bez PCA)\n",
        "# ------------------------\n",
        "\n",
        "all_def_embedings = []\n",
        "for x in all_word_definitions:\n",
        "    for y in all_word_definitions[x]:\n",
        "        all_def_embedings.append((x, Sentence_Embeding(y)))\n",
        "\n",
        "# ------------------------\n",
        "# Metryka cosine similarity\n",
        "# ------------------------\n",
        "\n",
        "def cosine_sim(v1, v2):\n",
        "    norm1 = np.linalg.norm(v1)\n",
        "    norm2 = np.linalg.norm(v2)\n",
        "    if norm1 == 0 or norm2 == 0:\n",
        "        return 0\n",
        "    return np.dot(v1, v2) / (norm1 * norm2)\n",
        "\n",
        "# ------------------------\n",
        "# Odpowiadanie na zagadkę z metryką cosine similarity\n",
        "# ------------------------\n",
        "\n",
        "def answer_riddle(riddle, K):\n",
        "    riddle_vector = Sentence_Embeding(riddle)\n",
        "    distances = []\n",
        "    for definition, definition_vector in all_def_embedings:\n",
        "        sim = cosine_sim(riddle_vector, definition_vector)\n",
        "        distances.append((sim, definition))\n",
        "    distances.sort(key=lambda x: x[0], reverse=True)  # Wyższa podobieństwo = lepsze\n",
        "    ans = [definition for _, definition in distances[:K]]\n",
        "    return ans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU2RlzFHlYHO"
      },
      "source": [
        "# Ewaluacja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_JLvfxplYHO"
      },
      "source": [
        "Poniższy kod będzie służył ewaluacji rozwiązania. Po wysłaniu rozwiązania do nas zostanie wykonana funkcja `evaluate_algorithm(score_function, queries, answers, K)`, t.j. prawie identyczny kod jak niżej będzie się uruchamiał na katalogu danych `test_data` dostępnym tylko dla sprawdzających zadania.\n",
        "\n",
        "Upewnij się przed wysłaniem, że cały notebook wykonuje się od początku do końca bez błędów i bez ingerencji użytkownika po wykonaniu polecenia `Run All`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SvKF4Dw3lYHO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Zmodyfikowana funkcja evaluate_algorithm\n",
        "def evaluate_algorithm(score_function, queries, answers, K):\n",
        "    computed_answers = []\n",
        "    data_for_csv = []\n",
        "\n",
        "    for query, real_answer in zip(queries, answers):\n",
        "        # Generujemy odpowiedzi za pomocą naszego algorytmu\n",
        "        predicted_answers = score_function(set(query), K=K)\n",
        "\n",
        "        # Obliczamy punkty za to pytanie\n",
        "        if real_answer in predicted_answers[:K]:\n",
        "            pos = predicted_answers.index(real_answer) + 1\n",
        "            score = 1 / pos\n",
        "        else:\n",
        "            score = 0\n",
        "\n",
        "        # Zbieramy dane do zapisania: pytanie, prawidłowa odpowiedź, 20 najprawdopodobniejszych odpowiedzi, punkty\n",
        "        data_for_csv.append({\n",
        "            'Pytanie': ' '.join(query),  # Zagadka jako tekst\n",
        "            'Prawidłowa odpowiedź': real_answer,\n",
        "            '20 Najbardziej prawdopodobnych odpowiedzi': ', '.join(predicted_answers[:K]),\n",
        "            'Punkty': score\n",
        "        })\n",
        "\n",
        "        computed_answers.append(predicted_answers)\n",
        "\n",
        "    # Zapisywanie wyników do CSV\n",
        "    df = pd.DataFrame(data_for_csv)\n",
        "    df.to_excel('wyniki.xlsx', index=False)\n",
        "\n",
        "\n",
        "    # Obliczamy Mean Reciprocal Rank\n",
        "    mrr = mean_reciprocal_rank(answers, computed_answers, K=K)\n",
        "    print ('Mean Reciprocal Rank =', mrr)\n",
        "\n",
        "    return mrr\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLYn3YFMlYHP",
        "outputId": "7b5c7440-320b-4ddd-de1a-0be283b4f25e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Reciprocal Rank = 0.24584074155978178\n",
            "Mean Reciprocal Rank = 0.24584074155978178\n",
            "Score: 0.24584074155978178\n"
          ]
        }
      ],
      "source": [
        "######################### NIE ZMIENIAJ TEJ KOMÓRKI ##########################\n",
        "if not FINAL_EVALUATION_MODE:\n",
        "    PART_OF_DATA = 100\n",
        "    K = 20\n",
        "    valid_queries = queries[:PART_OF_DATA]\n",
        "    valid_answers = answers[:PART_OF_DATA]\n",
        "    score = evaluate_algorithm(answer_riddle, valid_queries, valid_answers, K=K)\n",
        "    print(f\"Score: {score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbRFmW3_pKWX",
        "outputId": "f097efa7-ce54-4816-98a4-7856497c3950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Przykładowe zagadki (zagadki_do_testow_clean.txt) =====\n",
            "\n",
            "Zagadka: tytuł noszony przez zwierzchnika zakonu kawalerów mieczowych lub zakonu krzyżackiego.\n",
            "Odpowiedź: komtur\n",
            "\n",
            "Zagadka: proces lub efekt oddzielania lub rozdzielania czegoś na części lub elementy.\n",
            "Odpowiedź: separacja\n",
            "\n",
            "Zagadka: naturalne pragnienie jedzenia, stanowi regulację podaż i spożycie pokarmów potrzebnych do utrzymania zdrowia i życia.\n",
            "Odpowiedź: apetyt\n",
            "\n",
            "Zagadka: punkt na powierzchni ziemi bezpośrednio nad miejscem, gdzie doszło do trzęsienia ziemi.\n",
            "Odpowiedź: epicentrum\n",
            "\n",
            "Zagadka: organizm żywy, który poluje na inne zwierzęta w celu zdobycia pożywienia.\n",
            "Odpowiedź: drapieżnik\n",
            "\n",
            "\n",
            "===== Przykładowe definicje słów (plwiktionary_definitions_clean.txt) =====\n",
            "\n",
            "Słowo: oprawa \n",
            "Definicja:  okładka książki, zeszytu itp.\n",
            "\n",
            "Słowo: marka \n",
            "Definicja:  znak\n",
            "\n",
            "Słowo: opieka \n",
            "Definicja:  dbanie o kogoś lub coś; {{wikipedia}}\n",
            "\n",
            "Słowo: zona \n",
            "Definicja:  ''3. {{os}} {{lp}} czasu teraźniejszego trybu oznajmującego (presente do indicativo) czasownika'' zonar\n",
            "\n",
            "Słowo: odchody \n",
            "Definicja:  {{fizj}} stałe pozostałości trawienne i ciekłe, produkty przemiany materii wydalane jako kał i mocz\n",
            "\n",
            "\n",
            "===== Przykładowe formy bazowe (superbazy_clean.txt) =====\n",
            "\n",
            "Słowo odmienione: demilitaryzujże\n",
            "Forma bazowa: demilitaryzować\n",
            "\n",
            "Słowo odmienione: zafurczałeś\n",
            "Forma bazowa: zafurczeć\n",
            "\n",
            "Słowo odmienione: uświadomicie\n",
            "Forma bazowa: uświadomić\n",
            "\n",
            "Słowo odmienione: efektywniejszych\n",
            "Forma bazowa: efektywniejszy\n",
            "\n",
            "Słowo odmienione: toksykologiczna\n",
            "Forma bazowa: toksykologiczny\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Wyświetlenie przykładowych danych z plików\n",
        "\n",
        "import random\n",
        "\n",
        "# Wyświetlenie 5 przykładowych zagadek\n",
        "print(\"===== Przykładowe zagadki (zagadki_do_testow_clean.txt) =====\\n\")\n",
        "with open(f'{path_to_data}/zagadki/zagadki_do_testow_clean.txt', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in random.sample(lines, 5):\n",
        "        answer, *riddle = line.strip().replace(';;','').split()\n",
        "        print(f\"Zagadka: {' '.join(riddle)}\\nOdpowiedź: {answer}\\n\")\n",
        "\n",
        "# Wyświetlenie 5 przykładowych definicji\n",
        "print(\"\\n===== Przykładowe definicje słów (plwiktionary_definitions_clean.txt) =====\\n\")\n",
        "with open(f'{path_to_data}/zagadki/plwiktionary_definitions_clean.txt', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in random.sample(lines, 5):\n",
        "        word, definition = line.strip().split(\"###\")\n",
        "        print(f\"Słowo: {word}\\nDefinicja: {definition}\\n\")\n",
        "\n",
        "# Wyświetlenie 5 przykładowych bazowych form słów\n",
        "print(\"\\n===== Przykładowe formy bazowe (superbazy_clean.txt) =====\\n\")\n",
        "with open(f'{path_to_data}/zagadki/superbazy_clean.txt', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "    for line in random.sample(lines, 5):\n",
        "        word, base = line.strip().split()\n",
        "        print(f\"Słowo odmienione: {word}\\nForma bazowa: {base}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRd5WGSiZf_u",
        "outputId": "0dd5b119-d849-4832-ef8c-eeb8e8f59aea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Liczba wierszy bez punktów: 46\n",
            "Liczba wierszy z jakimikolwiek punktami (>0): 54\n",
            "Liczba wierszy z dokładnie 1 punktem: 15\n",
            "Łączna liczba wierszy: 100\n",
            "Odsetek idealnie trafionych (1 punkt): 15.00%\n",
            "Odsetek zagadek z jakimikolwiek punktami: 54.00%\n"
          ]
        }
      ],
      "source": [
        "# Wczytanie pliku\n",
        "df = pd.read_excel('wyniki.xlsx')\n",
        "\n",
        "# Podstawowe liczenie\n",
        "liczba_z_punktami = (df['Punkty'] > 0).sum()\n",
        "liczba_z_jednym_punktem = (df['Punkty'] == 1).sum()\n",
        "liczba_bez_punktow = (df['Punkty'] == 0).sum()\n",
        "\n",
        "print(f'Liczba wierszy bez punktów: {liczba_bez_punktow}')\n",
        "print(f'Liczba wierszy z jakimikolwiek punktami (>0): {liczba_z_punktami}')\n",
        "print(f'Liczba wierszy z dokładnie 1 punktem: {liczba_z_jednym_punktem}')\n",
        "\n",
        "print(f'Łączna liczba wierszy: {len(df)}')\n",
        "print(f'Odsetek idealnie trafionych (1 punkt): {liczba_z_jednym_punktem / len(df) * 100:.2f}%')\n",
        "print(f'Odsetek zagadek z jakimikolwiek punktami: {liczba_z_punktami / len(df) * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBY5AAwIABJ2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
